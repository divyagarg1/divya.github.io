<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>StopHarass</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	</head>
	<body>

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="/">Home</a></li>
					<li><a href="#top">Overview</a></li>
					<li><a href="#research">Research</a></li>
					<li><a href="#design">Design</a></li>
				</ul>
			</nav>

		<!-- Home -->
			<div class="wrapper style1 first">
							<header>
								<h1>Overview</h1>
							</header>
				<article class="container" id="top">
					<div class="row">
						<div class="12u 12u(mobile)">
							<p>The anonymity of social media provides a convenient façade to online harassment. This is especially seen in communities or social media platforms that are driven by user generated content. Current methods of handling such content, especially comments is either through an architectural design on the platform such as blocking or flagging or the use of moderators to sift through content. In this project, we explore using an algorithmic approach to support moderation by humans. This is done by mining for insults in social media, so that the comments that are identified as insults, can be automatically flagged for review and prioritized, thereby ensuring quicker action by moderators.</p>
						</div>
					</div>
				</article>
			</div>

		<!-- Work -->
			<div class="wrapper style2">
				<article id="research">
					<header>
						<h1>Research</h1>
            		</header>
            		<div class="container">
						<div class="row">
							<div class="12u 12u(mobile)">
								<p>We did some reasearch and literature review on the current trend  and the current solutions for preventing online harassment. A 2014 study by Pew research center showed that 40% of internet users have personally experienced online harassment, from the mild to the severe; 73% have witnessed it occur to others.</p>
								Current options of dealing with trolls online are threefold. One, using architectural elements such as blocking the user or flagging the comment that is prevalent on many social platforms. Two, by using Moderation, such as by using algorithms to identify vandals on Wikipedia.  Three, using the social conventions on the social platforms to encourage or discourage users. </p>          
                <p>All the above solutions are reactive in nature and the damage is already done to the victim. Our approach is to prevent harassment in the first place by detecting insults when a user is posting or commenting and providing them a warning notification that might change the mind of the user. If the user continued to post insulting comments, it would still be flagged for review and prioritized, thereby ensuring quicker action by moderators.</p>
							</div>
						</div>
					</div>
				</article>
			</div>

		<!-- Portfolio -->
			<div class="wrapper style3">
				<article id="design">
					<header>
						<h1>Design</h1>
					</header>
					<div class="container">
						<div class="row">
							<div class="12u 12u(mobile)">
								
          <p>All of our analysis is based on two sources of data for social media comments: A dataset provided by Kaggle  and a public stream of data obtained from the Twitter API. The Kaggle dataset  correspond to 3,947 comments made in social media sites (unicode-escaped strings, all written in english language), each with a label of “insulting comment” (integer value of 1) or “neutral comment” (value of 0).
In the quest of finding a good classifier model, we experiment with Naïve Bayes and Logistic regression, and focus our efforts into finding adequate “featurizations” of our data. Fatures that we used for Kaggle data set were Using unigrams
Using unigrams, bi-grams and tri-grams and N-grams along with additional features like the number of bad words (google list), ratio of words in the ‘bad list’, ratio of words in ALL CAPS</p>
								<p>Results were:</p>							
			<img style='width:100%;' border="0" alt="Null" src="stopHarass/images/result.png">

<p>Twitter data was obtained through their API to access a set of 600 public stream of Tweets. Since this randomly obtained stream of data did not contain a sufficient amount of insults, it was complemented with 100 tweets obtained from an account dedicated to stream insults . Each Twitter comment was manually labeled (insult/neutral) by 3 Amazon Turkers. Twitter data was manually labeled (insult/neutral) and reviewed to delete non-language (links, pictures), pornographic or non-english comments and randomly combined to obtain a proportion of 30-70% of insults/neutral comments. The final dataset contained 200 tweets with 60 (30%) of them labeled as insults. Using the same features, we were able to get 82% accuracy in the results.</p>
								<p>Future Wok:</p>
<p>We need to improve accuracy by including features like parts of speech (context), collocation etc. so that the subjectivity of insults can be understood. Also, we need to productize it into our vision of a mechanism for preventing online harassment. Our research paper can be found <a href="https://drive.google.com/drive/folders/0B94bUIQGEkfFQ29POE9Ya3gtbnc">here!</a></p>
							</div>
					</div>
				</div>
					
				</article>
			</div>
			<!-- Contact -->
			<div class="wrapper style4">
				<article id="contact" class="container 75%">
					<header>
						<h2>Connect with me!</h2>
					</header>
						<div class="row">
							<div class="12u 12u(mobile)">
								<font size="5"><b style="color:white"> <i class="fa fa-phone" aria-hidden="true"> 510-944-9190 </i> |  <i class="fa fa-envelope" aria-hidden="true"> <a href="mailto:divya.garg@berkeley.edu?subject=Hi">divya.garg@berkeley.edu</a> </i> |  </b><a href="https://www.linkedin.com/in/divyagarg2" class="icon fa-linkedin"><span class="label">LinkedIn</span></a> </font>
								<hr />
								<footer>
						<ul id="copyright">
							<li>©Divya Garg: All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>
							</div>
					</div>
					
				</article>
			</div>
			

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/skel-viewport.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
